{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3edf5a59-1c6d-4f88-904d-c4d88b7520f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Downloading Record 100 from Internet (PhysioNet)...\n",
      "‚úÖ '100.csv' file successfully created.\n",
      "\n",
      "‚öôÔ∏è Loading Model...\n",
      "‚úÖ System Ready! Model loaded.\n",
      "\n",
      "üìÇ Reading 100.csv...\n",
      "\n",
      "==============================\n",
      "üìä DIAGNOSIS REPORT\n",
      "==============================\n",
      "Total Beats:     2269\n",
      "Abnormal Beats:  2\n",
      "‚ù§Ô∏è Heart Rate:    75 BPM\n",
      "Risk Score:      0.09%\n",
      "------------------------------\n",
      "\n",
      "üü¢ RESULT: NORMAL RHYTHM\n"
     ]
    }
   ],
   "source": [
    " # ============================\n",
    "# Notebook 08: Final Prediction \n",
    "# ============================\n",
    "\n",
    "import wfdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 1: INTERNET SE DATA LEKAR CSV BANANA\n",
    "# ---------------------------------------------------------\n",
    "print(\"üåê Downloading Record 100 from Internet (PhysioNet)...\")\n",
    "try:\n",
    "    # Internet se Record 100 download karna\n",
    "    record = wfdb.rdrecord('100', pn_dir='mitdb')\n",
    "    \n",
    "    # Sirf pehla signal lena (MLII lead)\n",
    "    signal_data = record.p_signal[:, 0]\n",
    "    \n",
    "    # CSV file banana (Taaki model padh sake)\n",
    "    pd.DataFrame(signal_data).to_csv(\"100.csv\", index=False, header=False)\n",
    "    print(\"‚úÖ '100.csv' file successfully created.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Internet Error: {e}\")\n",
    "    # Agar internet nahi chala to fake signal banayenge testing ke liye\n",
    "    signal_data = np.sin(np.linspace(0, 10, 3600))\n",
    "    pd.DataFrame(signal_data).to_csv(\"100.csv\", index=False, header=False)\n",
    "    print(\"‚ö†Ô∏è Using Simulation Data instead.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 2: SYSTEM LOAD KARNA\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n‚öôÔ∏è Loading Model...\")\n",
    "try:\n",
    "    if not os.path.exists('models/rf_ecg_model.pkl'):\n",
    "        raise FileNotFoundError(\"Run Notebook 06 first to save the models!\")\n",
    "        \n",
    "    model = joblib.load('models/rf_ecg_model.pkl')\n",
    "    scaler = joblib.load('models/scaler.pkl')\n",
    "    print(\"‚úÖ System Ready! Model loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 3: FUNCTIONS DEFINE KARNA\n",
    "# ---------------------------------------------------------\n",
    "def preprocess_signal(raw_signal, fs=360):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(2, [0.5 / nyq, 40 / nyq], btype='band')\n",
    "    return filtfilt(b, a, raw_signal)\n",
    "\n",
    "def extract_features_from_signal(clean_signal, fs=360):\n",
    "    peaks, _ = signal.find_peaks(clean_signal, distance=int(0.6*fs), height=np.mean(clean_signal))\n",
    "    features_list = []\n",
    "    for i in range(1, len(peaks) - 1):\n",
    "        r_prev = peaks[i-1]; r_curr = peaks[i]; r_next = peaks[i+1]\n",
    "        rr_prev = (r_curr - r_prev) / fs\n",
    "        rr_next = (r_next - r_curr) / fs\n",
    "        \n",
    "        widths = signal.peak_widths(clean_signal, [r_curr], rel_height=0.5)\n",
    "        qrs_duration = widths[0][0] / fs\n",
    "        \n",
    "        window = int(0.05 * fs)\n",
    "        segment = clean_signal[max(0, r_curr-window):min(len(clean_signal), r_curr+window)]\n",
    "        \n",
    "        features_list.append({\n",
    "            \"RR_prev(s)\": rr_prev, \"RR_next(s)\": rr_next, \"QRS_duration(s)\": qrs_duration,\n",
    "            \"R_amp\": clean_signal[r_curr],\n",
    "            \"QRS_max\": np.max(segment) if len(segment)>0 else 0,\n",
    "            \"QRS_min\": np.min(segment) if len(segment)>0 else 0\n",
    "        })\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# STEP 4: PREDICTION & HEART RATE (MAIN PART)\n",
    "# ---------------------------------------------------------\n",
    "file_name = \"100.csv\"  # Ye file abhi Step 1 mein bani hai\n",
    "\n",
    "try:\n",
    "    # Read the file\n",
    "    print(f\"\\nüìÇ Reading {file_name}...\")\n",
    "    try:\n",
    "        new_data = pd.read_csv(file_name, header=None)\n",
    "        if isinstance(new_data.iloc[0,0], str): new_data = pd.read_csv(file_name)\n",
    "    except:\n",
    "        new_data = pd.read_csv(file_name)\n",
    "        \n",
    "    raw_signal = new_data.iloc[:, 0].values\n",
    "    \n",
    "    # Process\n",
    "    clean_sig = preprocess_signal(raw_signal)\n",
    "    features_df = extract_features_from_signal(clean_sig)\n",
    "\n",
    "    if features_df.empty:\n",
    "        print(\"‚ö†Ô∏è No heartbeats found.\")\n",
    "    else:\n",
    "        # Scale & Predict\n",
    "        X_input = features_df[[\"RR_prev(s)\", \"RR_next(s)\", \"QRS_duration(s)\", \"R_amp\", \"QRS_max\", \"QRS_min\"]]\n",
    "        X_scaled = scaler.transform(X_input)\n",
    "        predictions = model.predict(X_scaled)\n",
    "        \n",
    "        # --- ‚ù§Ô∏è HEART RATE CALCULATION ---\n",
    "        avg_rr_seconds = features_df[\"RR_prev(s)\"].mean()\n",
    "        bpm = int(60 / avg_rr_seconds)\n",
    "        # ---------------------------------\n",
    "\n",
    "        # Report Stats\n",
    "        abnormal = np.sum(predictions)\n",
    "        risk = (abnormal / len(predictions)) * 100\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(\"üìä DIAGNOSIS REPORT\")\n",
    "        print(\"=\"*30)\n",
    "        print(f\"Total Beats:     {len(predictions)}\")\n",
    "        print(f\"Abnormal Beats:  {abnormal}\")\n",
    "        print(f\"‚ù§Ô∏è Heart Rate:    {bpm} BPM\")    \n",
    "        print(f\"Risk Score:      {risk:.2f}%\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        if risk > 20:\n",
    "            print(\"\\nüî¥ RESULT: ARRHYTHMIA DETECTED\")\n",
    "        else:\n",
    "            print(\"\\nüü¢ RESULT: NORMAL RHYTHM\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315c51eb-f6a1-43be-b936-d61c547b3e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Files yahan save hongi: C:\\Users\\HP\\Desktop\\ECG_Arrhythmia_Project\\notebooks\n",
      "------------------------------\n",
      "‚è≥ Downloading Record 100...\n",
      "‚úÖ SUCCESS: File ban gayi! -> normal_patient.csv\n",
      "   (Size: 4708.66 KB)\n",
      "‚è≥ Downloading Record 200...\n",
      "‚úÖ SUCCESS: File ban gayi! -> abnormal_patient.csv\n",
      "   (Size: 4584.28 KB)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Main Folder ka rasta (Path) pata karna\n",
    "main_folder = os.getcwd() # Ye wahi folder hai jahan notebook hai\n",
    "print(f\"üìÇ Files yahan save hongi: {main_folder}\")\n",
    "\n",
    "# 2. Function file download karne ke liye\n",
    "def force_download_csv(record_id, filename):\n",
    "    full_path = os.path.join(main_folder, filename)\n",
    "    try:\n",
    "        print(f\"‚è≥ Downloading Record {record_id}...\")\n",
    "        record = wfdb.rdrecord(record_id, pn_dir='mitdb')\n",
    "        signal = record.p_signal[:, 0]\n",
    "        \n",
    "        # Save CSV\n",
    "        pd.DataFrame(signal).to_csv(full_path, index=False, header=False)\n",
    "        \n",
    "        # Check karna ki file bani ya nahi\n",
    "        if os.path.exists(full_path):\n",
    "            size = os.path.getsize(full_path)\n",
    "            print(f\"‚úÖ SUCCESS: File ban gayi! -> {filename}\")\n",
    "            print(f\"   (Size: {size/1024:.2f} KB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå ERROR: File nahi dikh rahi.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "\n",
    "# 3. Ab Download shuru karein\n",
    "print(\"-\" * 30)\n",
    "force_download_csv('100', 'normal_patient.csv')       # Normal\n",
    "force_download_csv('200', 'abnormal_patient.csv')     # Abnormal\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ecg_env)",
   "language": "python",
   "name": "ecg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
